{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageFilter\n",
    "import pytesseract\n",
    "\n",
    "# Path to your scanned textbook PDF\n",
    "PDF_PATH = \"/Users/minhajulhoque/work/github/mcps/genki_mcp/data/Genki Textbook 2nd Edition.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting and Saving the Scanned PDF Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF to images (you can batch this if memory is a concern)\n",
    "print(\"Converting PDF pages to images...\")\n",
    "pages = convert_from_path(PDF_PATH, dpi=300)\n",
    "\n",
    "print(f\"Total pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PIL Images under /data/pdf_images/\n",
    "import os\n",
    "\n",
    "def save_images_to_directory(images, output_dir=\"../data/pdf_images/\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        image_path = os.path.join(output_dir, f\"page_{idx + 1}.png\")\n",
    "        img.save(image_path, format=\"PNG\")\n",
    "        print(f\"Saved: {image_path}\")\n",
    "\n",
    "save_images_to_directory(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "\n",
    "for i, page in enumerate(pages[:37]):  # Limit to first 27 pages\n",
    "    print(f\"OCR on page {i + 1}/{min(len(pages), 37)}\")  # Adjust the print statement\n",
    "    \n",
    "    # Convert page to grayscale image\n",
    "    gray_page = page.convert(\"L\")\n",
    "\n",
    "    # OCR to extract text\n",
    "    text = pytesseract.image_to_string(gray_page)\n",
    "\n",
    "    all_text.append(f\"\\n\\n--- Page {i+1} ---\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_text[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Specific Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "\n",
    "for i, page in enumerate(pages[:37]):  # Limit to first 27 pages\n",
    "    print(f\"OCR on page {i + 1}/{min(len(pages), 37)}\")  # Adjust the print statement\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img = page.convert(\"L\")\n",
    "\n",
    "    # Optional: Image cleanup (denoise, sharpen)\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "    # OCR with English + Japanese\n",
    "    text = pytesseract.image_to_string(img, lang='eng+jpn')\n",
    "\n",
    "    all_text.append(f\"\\n\\n--- Page {i+1} ---\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_text[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "\n",
    "for i, page in enumerate(pages[:37]):  # Limit to first 27 pages\n",
    "    print(f\"OCR on page {i + 1}/{min(len(pages), 37)}\")  # Adjust the print statement\n",
    "\n",
    "    img = page.convert(\"L\")\n",
    "\n",
    "    # Optional image cleanup\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "    # Use layout preserving config\n",
    "    text = pytesseract.image_to_string(img, lang='eng+jpn', config='--psm 4')\n",
    "\n",
    "    all_text.append(f\"\\n\\n--- Page {i+1} ---\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_text[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on A Single Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B. Pair Work—Ask if your partner has done . . . yet. If the answer is no, ask your partner out, as in the example. (If yes, ask your partner how it was, as in (2).)\n",
      "\n",
      "Examples: the name of a newly released movie　「ワンピース」を見ました\n",
      "\n",
      "A：　「ワンピース」を見ましたか。\n",
      "B：　いいえ、まだです。\n",
      "A：　じゃあ、いっしょに見に行きませんか。\n",
      "\n",
      "A：　「ワンピース」を見ましたか。\n",
      "B：　はい、見ました。\n",
      "A：　どうでしたか。\n",
      "B：　とてもおもしろかったです。\n",
      "\n",
      "the name of a newly released movie\n",
      "the name of a new restaurant/café\n",
      "the name of a newly released song/music\n",
      "\n",
      "天気がいいから、海（うみ）に行きます\n",
      "\n",
      "A. Match up the phrases to make sense.\n",
      "\n",
      "1. 今日は天気がいいから、　　　　　a. うちに帰ります。\n",
      "2. たくさん勉強したから、　　　　　b. たくさん食べました。\n",
      "3. おなかがすいていたから、　　　　c. ねます。\n",
      "4. つかれていたから、　　　　　　　d. 海に行きます。\n",
      "\n",
      "1 ＿＿＿　2 ＿＿＿　3 ＿＿＿　4 ＿＿＿\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client with API key from .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/Users/minhajulhoque/work/github/mcps/genki_mcp/data/pdf_images/page_223.png\"\n",
    "\n",
    "GENKI_PDF_EXTRACTION_PROMPT = \"\"\"Extract both English and Japanese text accurately from the Genki textbook. The goal is to preserve the original content in a way that allows a student to understand the core lesson without seeing the textbook itself.\n",
    "\n",
    "Instructions:\n",
    "1.\tText Extraction:\n",
    "    • Extract all English text in clear, correct English.\n",
    "    • Extract all Japanese text in proper Japanese (use correct kana, kanji, and grammar).\n",
    "    • Do not translate between the two languages. Keep each language exactly as it appears.\n",
    "2.\tFormatting and Layout:\n",
    "    • Keep the original structure, spacing, and formatting as close to the textbook as possible.\n",
    "    • Example: If a sentence is on its own line in the book, keep it on its own line in the output.\n",
    "    • Maintain bullet points, dialogue structure, headings, and numbered items if present.\n",
    "    • This helps students easily follow along and compare content if needed.\n",
    "3.\tClarity and Comprehension:\n",
    "    • The extracted content should be clear and easy to understand for a beginner-level student.\n",
    "    • A student should be able to read your output and grasp the main ideas and structure of the Genki lesson without confusion.\n",
    "4.\tHandling Diagrams and Images:\n",
    "    • If the textbook includes diagrams, illustrations, or pictures:\n",
    "    • Briefly describe them in text only if the description helps the student understand the content better.\n",
    "    • Do not include descriptions if they add confusion or are unnecessary.\n",
    "        \n",
    "Notes:\n",
    "\t• Avoid spelling or grammar mistakes.\n",
    "\t• Do not paraphrase or summarize the content—extract it as-is.\n",
    "\t• Do not add any other commentary beside the extracted content.\n",
    "\t• Use your best judgment to decide whether describing a visual element is helpful.\n",
    "\"\"\"\n",
    "\n",
    "# Encode the image to base64\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "# Create the chat completion request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-2025-04-14\",  # gpt-4.1-mini-2025-04-14,  Use the correct full model name\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \"text\": GENKI_PDF_EXTRACTION_PROMPT },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"low\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on All Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Function to encode image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "GENKI_PDF_EXTRACTION_PROMPT = \"\"\"Extract both English and Japanese text accurately from the Genki textbook. The goal is to preserve the original content in a way that allows a student to understand the core lesson without seeing the textbook itself.\n",
    "\n",
    "Instructions:\n",
    "1.\tText Extraction:\n",
    "    • Extract all English text in clear, correct English.\n",
    "    • Extract all Japanese text in proper Japanese (use correct kana, kanji, and grammar).\n",
    "    • Do not translate between the two languages. Keep each language exactly as it appears.\n",
    "2.\tFormatting and Layout:\n",
    "    • Keep the original structure, spacing, and formatting as close to the textbook as possible.\n",
    "    • Example: If a sentence is on its own line in the book, keep it on its own line in the output.\n",
    "    • Maintain bullet points, dialogue structure, headings, and numbered items if present.\n",
    "    • This helps students easily follow along and compare content if needed.\n",
    "3.\tClarity and Comprehension:\n",
    "    • The extracted content should be clear and easy to understand for a beginner-level student.\n",
    "    • A student should be able to read your output and grasp the main ideas and structure of the Genki lesson without confusion.\n",
    "4.\tHandling Diagrams and Images:\n",
    "    • If the textbook includes diagrams, illustrations, or pictures:\n",
    "    • Briefly describe them in text only if the description helps the student understand the content better.\n",
    "    • Do not include descriptions if they add confusion or are unnecessary.\n",
    "        \n",
    "Notes:\n",
    "\t• Avoid spelling or grammar mistakes.\n",
    "\t• Do not paraphrase or summarize the content—extract it as-is.\n",
    "\t• Do not add any other commentary beside the extracted content.\n",
    "\t• Use your best judgment to decide whether describing a visual element is helpful.\n",
    "\"\"\"\n",
    "\n",
    "# Paths\n",
    "image_dir = \"/Users/minhajulhoque/work/github/mcps/genki_mcp/data/pdf_images/\"\n",
    "output_path = \"/Users/minhajulhoque/work/github/mcps/genki_mcp/output/extracted_text.json\"\n",
    "\n",
    "# Load existing extractions if they exist\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        extracted_pages = json.load(f)\n",
    "else:\n",
    "    extracted_pages = {}\n",
    "\n",
    "start_from = 0\n",
    "filtered_filenames = sorted(os.listdir(image_dir))[start_from:]\n",
    "\n",
    "print(\"Starting from\", filtered_filenames[0])\n",
    "\n",
    "# Process all image files in directory\n",
    "for filename in filtered_filenames:\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        page_number = os.path.splitext(filename)[0].replace(\"page_\", \"\")\n",
    "\n",
    "        # Skip if already processed\n",
    "        if page_number in extracted_pages:\n",
    "            print(f\"Skipping page {page_number} (already processed).\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        print(f\"Processing {filename}...\")\n",
    "\n",
    "        try:\n",
    "            base64_image = encode_image(image_path)\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            { \"type\": \"text\", \"text\": GENKI_PDF_EXTRACTION_PROMPT },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "\n",
    "            extracted_text = completion.choices[0].message.content\n",
    "            extracted_pages[page_number] = {\n",
    "                \"filename\": filename,\n",
    "                \"text\": extracted_text\n",
    "            }\n",
    "\n",
    "            # Save after each successful page\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(extracted_pages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Extraction finished. All progress saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which Pages Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pages is 383.\n",
      "No pages are missing.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace 'your_file.json' with the path to your JSON file\n",
    "with open('/Users/minhajulhoque/work/github/mcps/genki_mcp/output/extracted_text.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# The number of pages is the number of top-level keys\n",
    "number_of_pages = len(data)\n",
    "\n",
    "if number_of_pages == 383:\n",
    "    print(\"The number of pages is 383.\")\n",
    "else:\n",
    "    print(f\"The number of pages is {number_of_pages}, not 383.\")\n",
    "    \n",
    "# Find missing pages\n",
    "all_pages = set(str(i) for i in range(1, 384))\n",
    "found_pages = set(data.keys())\n",
    "missing_pages = sorted(int(p) for p in all_pages - found_pages)\n",
    "\n",
    "if missing_pages:\n",
    "    print(f\"Missing pages: {missing_pages}\")\n",
    "else:\n",
    "    print(\"No pages are missing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
